{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognizing Sentiment: Sarcasm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXjHQO8/543hUVXdbUcXMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shelvi31/Natural-Language-Processing/blob/main/Recognizing_Sentiment_Sarcasm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl-X-QJbAiI8"
      },
      "source": [
        "#importing\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11Zb9deEkH0"
      },
      "source": [
        "#Building classifier to Recognize sentiment and text -- Training a model to recognize sentiment in text \n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LaG23tAFe-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25da301-f219-47cb-b86f-02228514ee76"
      },
      "source": [
        "#About Dataset\n",
        "\n",
        "# Each record consists of three attributes:\n",
        "\n",
        "# is_sarcastic: 1 if the record is sarcastic otherwise 0\n",
        "# headline: the headline of the news article\n",
        "# article_link: link to the original news article. Useful in collecting supplementary data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zNTJVLUGLJX"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import json\n",
        "datastore = [json.loads(line) for line in open(\"/content/sample_data/Sarcasm_Headlines_Dataset_v2.json\", 'r')]    #need to upload this file everytime with new runtime\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for item in datastore:\n",
        "  sentences.append(item[\"headline\"])\n",
        "  labels.append(item[\"is_sarcastic\"])"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNPqPwvCa7Ge"
      },
      "source": [
        "#splitting data for training and testing\n",
        "\n",
        "training_size = 20000\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = sentences[training_size:]"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_8gvp58EMJ-"
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 100"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCG2VbgJG-L6"
      },
      "source": [
        "#lets do pre processing on the text\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000,oov_token=\"<OOV>\")   #alloting tokens to words\n",
        "\n",
        "#asking tokenizer to go to text and fix them in sentences     \n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "  \n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "#TRAINING\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=\"post\", truncating='post')\n",
        "\n",
        "#TESTING\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFB5ekY6Ullz"
      },
      "source": [
        "# Need this block to get it to work with TensorFlow 2.x\n",
        "\n",
        "import numpy as np\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFYp0Ar7JLMU"
      },
      "source": [
        ""
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONOhiikPaSEk"
      },
      "source": [
        "#Here is the neural network : for more clarity on concept : https://www.youtube.com/watch?v=Y_hzMnRXjhI&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=3\n",
        "from keras.layers import Embedding\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length = max_length),  #Embedding : Direction of each word (sarcastic or not) would be learnt epoch by epoch\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),   #Pool with global avg pooling : i.e adding vectors (direction of words)\n",
        "#Feeding it to a neural network\n",
        "        tf.keras.layers.Dense(24,activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEWm3VloWYP_",
        "outputId": "5ce2bbce-9b08-45bc-de58-2dab50f459ec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 100, 16)           160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_13  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 160,433\n",
            "Trainable params: 160,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezwK8zAMWSxB",
        "outputId": "c00d1b75-3af4-4216-be11-0ec84b968786"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "model.fit(training_padded, training_labels, epochs=20, verbose=2)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 - 2s - loss: 0.0233 - accuracy: 0.9941\n",
            "Epoch 2/20\n",
            "625/625 - 2s - loss: 0.0230 - accuracy: 0.9944\n",
            "Epoch 3/20\n",
            "625/625 - 2s - loss: 0.0207 - accuracy: 0.9952\n",
            "Epoch 4/20\n",
            "625/625 - 2s - loss: 0.0174 - accuracy: 0.9959\n",
            "Epoch 5/20\n",
            "625/625 - 2s - loss: 0.0190 - accuracy: 0.9952\n",
            "Epoch 6/20\n",
            "625/625 - 2s - loss: 0.0168 - accuracy: 0.9964\n",
            "Epoch 7/20\n",
            "625/625 - 2s - loss: 0.0169 - accuracy: 0.9956\n",
            "Epoch 8/20\n",
            "625/625 - 2s - loss: 0.0135 - accuracy: 0.9969\n",
            "Epoch 9/20\n",
            "625/625 - 2s - loss: 0.0145 - accuracy: 0.9962\n",
            "Epoch 10/20\n",
            "625/625 - 2s - loss: 0.0128 - accuracy: 0.9969\n",
            "Epoch 11/20\n",
            "625/625 - 2s - loss: 0.0133 - accuracy: 0.9965\n",
            "Epoch 12/20\n",
            "625/625 - 2s - loss: 0.0109 - accuracy: 0.9973\n",
            "Epoch 13/20\n",
            "625/625 - 2s - loss: 0.0094 - accuracy: 0.9979\n",
            "Epoch 14/20\n",
            "625/625 - 2s - loss: 0.0093 - accuracy: 0.9979\n",
            "Epoch 15/20\n",
            "625/625 - 2s - loss: 0.0107 - accuracy: 0.9973\n",
            "Epoch 16/20\n",
            "625/625 - 2s - loss: 0.0091 - accuracy: 0.9977\n",
            "Epoch 17/20\n",
            "625/625 - 2s - loss: 0.0097 - accuracy: 0.9971\n",
            "Epoch 18/20\n",
            "625/625 - 2s - loss: 0.0087 - accuracy: 0.9977\n",
            "Epoch 19/20\n",
            "625/625 - 2s - loss: 0.0109 - accuracy: 0.9967\n",
            "Epoch 20/20\n",
            "625/625 - 2s - loss: 0.0072 - accuracy: 0.9985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6adb9ad910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3wbRaz6WVDP",
        "outputId": "9762af3d-ec72-47d5-cd7d-34c96f8889e6"
      },
      "source": [
        "sentence = [\"granny starting to fear spiders in the garden might be real\", \n",
        "            \"game of thrones season finale showing this sunday night\"]\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
        "print(model.predict(padded))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.8571622e-01]\n",
            " [2.8493918e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSaFeVgIMt5j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}